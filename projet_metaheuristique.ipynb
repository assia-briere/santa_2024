{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":88046,"databundleVersionId":10229277,"sourceType":"competition"},{"sourceId":104492,"sourceType":"modelInstanceVersion","modelInstanceId":72255,"modelId":76277}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T14:59:58.124819Z","iopub.execute_input":"2024-12-09T14:59:58.125250Z","iopub.status.idle":"2024-12-09T14:59:59.479756Z","shell.execute_reply.started":"2024-12-09T14:59:58.125215Z","shell.execute_reply":"2024-12-09T14:59:59.478333Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/santa-2024/sample_submission.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.model_download(\"google/gemma-2/transformers/gemma-2-9b\")\n\nprint(\"Path to model files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:20:20.595395Z","iopub.execute_input":"2024-12-21T20:20:20.595846Z","iopub.status.idle":"2024-12-21T20:20:21.578650Z","shell.execute_reply.started":"2024-12-21T20:20:20.595818Z","shell.execute_reply":"2024-12-21T20:20:21.577691Z"}},"outputs":[{"name":"stdout","text":"Path to model files: /kaggle/input/gemma-2/transformers/gemma-2-9b/2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"/kaggle/input/gemma-2/transformers/gemma-2-9b/2/\",\n    device_map=\"auto\",\n    torch_dtype=torch.bfloat16\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:20:21.579745Z","iopub.execute_input":"2024-12-21T20:20:21.579996Z","iopub.status.idle":"2024-12-21T20:23:10.123030Z","shell.execute_reply.started":"2024-12-21T20:20:21.579968Z","shell.execute_reply":"2024-12-21T20:23:10.122364Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddca30c0bc5249cea33d98a279a38a8d"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\n    \"/kaggle/input/gemma-2/transformers/gemma-2-9b/2/\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:23:10.125475Z","iopub.execute_input":"2024-12-21T20:23:10.126396Z","iopub.status.idle":"2024-12-21T20:23:11.371068Z","shell.execute_reply.started":"2024-12-21T20:23:10.126367Z","shell.execute_reply":"2024-12-21T20:23:11.370153Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Charger les données\ndata = pd.read_csv('/kaggle/input/santa-2024/sample_submission.csv')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:23:11.372299Z","iopub.execute_input":"2024-12-21T20:23:11.372668Z","iopub.status.idle":"2024-12-21T20:23:11.388813Z","shell.execute_reply.started":"2024-12-21T20:23:11.372629Z","shell.execute_reply":"2024-12-21T20:23:11.388162Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import torch\n\n\n# Configuration du périphérique\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:23:11.389738Z","iopub.execute_input":"2024-12-21T20:23:11.389986Z","iopub.status.idle":"2024-12-21T20:23:11.394019Z","shell.execute_reply.started":"2024-12-21T20:23:11.389961Z","shell.execute_reply":"2024-12-21T20:23:11.393201Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Fonction pour calculer la perplexité\ndef calculate_perplexity(sequence):\n    input_ids = tokenizer(sequence, return_tensors=\"pt\").input_ids.to(device)  # Déplacer les données sur le bon périphérique\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, labels=input_ids)  # Assurez-vous que le modèle et les données sont sur le même périphérique\n        loss = outputs.loss\n    return torch.exp(loss).item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:23:11.394994Z","iopub.execute_input":"2024-12-21T20:23:11.395286Z","iopub.status.idle":"2024-12-21T20:23:11.405369Z","shell.execute_reply.started":"2024-12-21T20:23:11.395261Z","shell.execute_reply":"2024-12-21T20:23:11.404677Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import random\n\n# Initialiser les paramètres de l'algorithme génétique\nPOPULATION_SIZE = 50  # Taille de la population\nGENERATIONS = 100     # Nombre d'itérations\nMUTATION_RATE = 0.2   # Probabilité de mutation\nCROSSOVER_RATE = 0.8  # Probabilité de croisement\nTOURNAMENT_SIZE = 5   # Taille pour la sélection par tournoi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:23:11.408867Z","iopub.execute_input":"2024-12-21T20:23:11.409115Z","iopub.status.idle":"2024-12-21T20:23:11.418219Z","shell.execute_reply.started":"2024-12-21T20:23:11.409090Z","shell.execute_reply":"2024-12-21T20:23:11.417578Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Fonction pour générer un individu (une permutation aléatoire)\ndef generate_individual(words):\n    return random.sample(words, len(words))\n\n# Fonction pour générer une population initiale\ndef generate_population(words, size):\n    return [generate_individual(words) for _ in range(size)]\n\n# Fonction de fitness (perplexité)\ndef fitness(individual):\n    sequence = \" \".join(individual)\n    perplexity = calculate_perplexity(sequence)\n    return perplexity  # Minimiser la perplexité","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:23:11.421230Z","iopub.execute_input":"2024-12-21T20:23:11.421459Z","iopub.status.idle":"2024-12-21T20:23:11.430113Z","shell.execute_reply.started":"2024-12-21T20:23:11.421430Z","shell.execute_reply":"2024-12-21T20:23:11.429314Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Sélection par tournoi\ndef tournament_selection(population, fitness_scores):\n    selected = []\n    for _ in range(len(population)):\n        tournament_size = min(TOURNAMENT_SIZE, len(population))\n        tournament = random.sample(list(zip(population, fitness_scores)), tournament_size)\n        best_individual = min(tournament, key=lambda x: x[1])  # Minimiser fitness\n        selected.append(best_individual[0])\n    return selected","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:23:11.431044Z","iopub.execute_input":"2024-12-21T20:23:11.431300Z","iopub.status.idle":"2024-12-21T20:23:11.445009Z","shell.execute_reply.started":"2024-12-21T20:23:11.431276Z","shell.execute_reply":"2024-12-21T20:23:11.444215Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def pmx_crossover(parent1, parent2):  \n    size = len(parent1)  \n    # Randomly select two points to define a segment  \n    start, end = sorted(random.sample(range(size), 2))  \n    \n    # Step 1: Copy the segment from parent1 into the child  \n    child = [None] * size  \n    child[start:end] = parent1[start:end]  \n\n    # Step 2: Create a mapping from parent2 to parent1  \n    mapping = {}  \n    for i in range(start, end):  \n        mapping[parent1[i]] = parent2[i]  \n\n    # Step 3: Fill the remaining positions in the child with parent2 values  \n    for i in range(size):  \n        if child[i] is None:  \n            current_word = parent2[i]  \n            while current_word in mapping:  # Resolve conflicts by following the mapping  \n                current_word = mapping[current_word]  \n            child[i] = current_word  \n\n    # Return the child  \n    return child","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:23:11.446011Z","iopub.execute_input":"2024-12-21T20:23:11.446334Z","iopub.status.idle":"2024-12-21T20:23:11.456967Z","shell.execute_reply.started":"2024-12-21T20:23:11.446291Z","shell.execute_reply":"2024-12-21T20:23:11.456351Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Mutation par échange (Swap Mutation)\ndef mutate(individual):\n    if random.random() < MUTATION_RATE:\n        i, j = random.sample(range(len(individual)), 2)\n        individual[i], individual[j] = individual[j], individual[i]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:23:11.457948Z","iopub.execute_input":"2024-12-21T20:23:11.458245Z","iopub.status.idle":"2024-12-21T20:23:11.467908Z","shell.execute_reply.started":"2024-12-21T20:23:11.458216Z","shell.execute_reply":"2024-12-21T20:23:11.467196Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Implémentation de la recherche locale (Gradient Descent)\ndef local_search(best_individual, max_iterations=10):\n    current_individual = best_individual[:]\n    current_fitness = fitness(current_individual)\n\n    for _ in range(max_iterations):\n        improved = False\n        for i in range(len(current_individual)):\n            for j in range(i + 1, len(current_individual)):\n                # Swap two elements\n                current_individual[i], current_individual[j] = current_individual[j], current_individual[i]\n                new_fitness = fitness(current_individual)\n\n                if new_fitness < current_fitness:  # We found a better arrangement\n                    current_fitness = new_fitness\n                    improved = True\n                else:\n                    # Swap back if it doesn't improve\n                    current_individual[i], current_individual[j] = current_individual[j], current_individual[i]\n\n        if not improved:\n            break  # No improvements, exit loop\n\n    return current_individual, current_fitness","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:23:11.469545Z","iopub.execute_input":"2024-12-21T20:23:11.469837Z","iopub.status.idle":"2024-12-21T20:23:11.481940Z","shell.execute_reply.started":"2024-12-21T20:23:11.469812Z","shell.execute_reply":"2024-12-21T20:23:11.480820Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def genetic_algorithm(words, generations, population_size):  \n    population = generate_population(words, population_size)  \n    min_perplexity = float('inf')  \n    min_sequence = None  # To store the best sequence\n\n    for generation in range(generations):  \n        fitness_scores = [fitness(ind) for ind in population]  \n\n        best_fitness_index = fitness_scores.index(min(fitness_scores))  \n        best_individual = population[best_fitness_index]  \n        best_sequence = ' '.join(best_individual)  \n        best_fitness = fitness_scores[best_fitness_index]  \n\n        # Update minimum perplexity \n        if best_fitness < min_perplexity:\n            min_perplexity = best_fitness\n            min_sequence = best_sequence  \n        selected_population = tournament_selection(population, fitness_scores)  \n\n        new_population = []  \n        for i in range(0, len(selected_population), 2):  \n            if i + 1 < len(selected_population) and random.random() < CROSSOVER_RATE:  \n                parent1, parent2 = selected_population[i], selected_population[i + 1]  \n                child1 = pmx_crossover(parent1, parent2)  \n                child2 = pmx_crossover(parent2, parent1)  \n                new_population.extend([child1, child2])  \n            else:  \n                new_population.append(selected_population[i])  \n\n        for individual in new_population:  \n            mutate(individual)  \n\n        population = new_population  \n\n    # Return the best solution found and its perplexity\n    return min_perplexity, min_sequence  \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:23:11.483336Z","iopub.execute_input":"2024-12-21T20:23:11.483990Z","iopub.status.idle":"2024-12-21T20:23:11.493556Z","shell.execute_reply.started":"2024-12-21T20:23:11.483959Z","shell.execute_reply":"2024-12-21T20:23:11.492699Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"sequences = data['text'].values.tolist() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T20:23:11.494743Z","iopub.execute_input":"2024-12-21T20:23:11.495076Z","iopub.status.idle":"2024-12-21T20:23:11.511715Z","shell.execute_reply.started":"2024-12-21T20:23:11.495036Z","shell.execute_reply":"2024-12-21T20:23:11.510953Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Appliquer l'algorithme génétique à chaque séquence\nfor idx, sequence in enumerate(sequences):\n    print(f\"\\nProcessing sequence {idx + 1}/{len(sequences)}: {sequence}\")\n    words = [word for word in sequence.split() if word is not None]\n    if not words:\n        print(f\"Skipping empty sequence: {sequence}\")\n        continue\n\n    try:\n        best_perplexity, best_sequence = genetic_algorithm(words, GENERATIONS, POPULATION_SIZE)\n    except Exception as e:\n        print(f\"Error processing sequence {idx + 1}: {e}\")\n        continue\n\n    print(f\"\\n=== Best sequence for current input ===\")\n    print(f\"Best Sequence: '{best_sequence}'\")\n    print(f\"Minimum Perplexity: {best_perplexity}\\n\")  # Display only the best perplexity and sequence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T15:14:34.910307Z","iopub.execute_input":"2024-12-21T15:14:34.911407Z","iopub.status.idle":"2024-12-21T16:38:45.109573Z","shell.execute_reply.started":"2024-12-21T15:14:34.911364Z","shell.execute_reply":"2024-12-21T16:38:45.108053Z"}},"outputs":[{"name":"stdout","text":"\nProcessing sequence 1/6: advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge\n\n=== Best sequence for current input ===\nBest Sequence: 'reindeer mistletoe elf scrooge gingerbread chimney fireplace ornament family advent'\nMinimum Perplexity: 486.9385986328125\n\n\nProcessing sequence 2/6: advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge walk give jump drive bake the sleep night laugh and\n\n=== Best sequence for current input ===\nBest Sequence: 'ornament advent bake the gingerbread sleep walk scrooge give elf family reindeer mistletoe night drive jump and laugh chimney fireplace'\nMinimum Perplexity: 1580.788818359375\n\n\nProcessing sequence 3/6: yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice\n\n=== Best sequence for current input ===\nBest Sequence: 'sleigh magi holly yuletide grinch polar workshop gifts nutcracker chimney stocking cheer carol holiday jingle naughty beard ornament decorations nice'\nMinimum Perplexity: 602.8138427734375\n\n\nProcessing sequence 4/6: yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice sing cheer and of the is eat visit relax unwrap\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     best_perplexity, best_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mgenetic_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGENERATIONS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPOPULATION_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing sequence \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[16], line 25\u001b[0m, in \u001b[0;36mgenetic_algorithm\u001b[0;34m(words, generations, population_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(selected_population) \u001b[38;5;129;01mand\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m CROSSOVER_RATE:  \n\u001b[1;32m     24\u001b[0m     parent1, parent2 \u001b[38;5;241m=\u001b[39m selected_population[i], selected_population[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]  \n\u001b[0;32m---> 25\u001b[0m     child1 \u001b[38;5;241m=\u001b[39m \u001b[43mpmx_crossover\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent2\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     26\u001b[0m     child2 \u001b[38;5;241m=\u001b[39m pmx_crossover(parent2, parent1)  \n\u001b[1;32m     27\u001b[0m     new_population\u001b[38;5;241m.\u001b[39mextend([child1, child2])  \n","Cell \u001b[0;32mIn[15], line 19\u001b[0m, in \u001b[0;36mpmx_crossover\u001b[0;34m(parent1, parent2)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m child[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \n\u001b[1;32m     18\u001b[0m     current_word \u001b[38;5;241m=\u001b[39m parent2[i]  \n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m current_word \u001b[38;5;129;01min\u001b[39;00m mapping:  \u001b[38;5;66;03m# Resolve conflicts by following the mapping  \u001b[39;00m\n\u001b[1;32m     20\u001b[0m         current_word \u001b[38;5;241m=\u001b[39m mapping[current_word]  \n\u001b[1;32m     21\u001b[0m     child[i] \u001b[38;5;241m=\u001b[39m current_word  \n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":17},{"cell_type":"markdown","source":"# **Malheureusement, le processus ne se termine pas en raison des interruptions liées à l'arrêt du kernel. Pour éviter de relancer le processus depuis le début, ce qui prendrait beaucoup de temps, nous avons décidé de continuer séquentiellement, sequence par sequence par sequence.**","metadata":{}},{"cell_type":"code","source":"sequence = data['text'][3]\nsequence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T21:56:43.892023Z","iopub.execute_input":"2024-12-21T21:56:43.892882Z","iopub.status.idle":"2024-12-21T21:56:43.898625Z","shell.execute_reply.started":"2024-12-21T21:56:43.892845Z","shell.execute_reply":"2024-12-21T21:56:43.897759Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice sing cheer and of the is eat visit relax unwrap'"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"if sequence is None or not isinstance(sequence, str):\n\n    print(f\"Skipping invalid sequence: {sequence}\")\n\nelse:\n\n    print(f\"Original sequence: {sequence}\")\n\n    words = [word.strip() for word in sequence.split() if word and isinstance(word, str)]\n\n    \n\n    if not words:\n\n        print(f\"Skipping empty or invalid sequence: {sequence}\")\n\n    else:\n\n        print(f\"Words after split and filter: {words}\")\n\n        try:\n\n            best_sequence, best_perplexity, generation_results = genetic_algorithm(words, GENERATIONS, POPULATION_SIZE)\n\n        except Exception as e:\n\n            print(f\"Error processing sequence: {e}\")\n\n            print(f\"Sequence: {sequence}\")\n\n            print(f\"Words: {words}\")\n\n        else:\n\n            print(f\"\\n=== Best sequence for current input ===\")\n\n            print(f\"Best Sequence: {' '.join(best_sequence)}\")\n\n            print(f\"Best Perplexity: {best_perplexity}\\n\")\n\n            # Afficher les résultats de chaque génération\n\n            for generation, fitness_value, seq in generation_results:\n\n                print(f\"Generation {generation}: Fitness = {fitness_value}, Sequence = '{seq}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T21:57:20.661968Z","iopub.execute_input":"2024-12-21T21:57:20.662360Z"}},"outputs":[{"name":"stdout","text":"Original sequence: yuletide decorations gifts cheer holiday carol magi nutcracker polar grinch sleigh chimney workshop stocking ornament holly jingle beard naughty nice sing cheer and of the is eat visit relax unwrap\nWords after split and filter: ['yuletide', 'decorations', 'gifts', 'cheer', 'holiday', 'carol', 'magi', 'nutcracker', 'polar', 'grinch', 'sleigh', 'chimney', 'workshop', 'stocking', 'ornament', 'holly', 'jingle', 'beard', 'naughty', 'nice', 'sing', 'cheer', 'and', 'of', 'the', 'is', 'eat', 'visit', 'relax', 'unwrap']\n","output_type":"stream"}],"execution_count":null}]}